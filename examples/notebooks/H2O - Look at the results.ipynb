{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Table of Contents\n",
    "* [Get access to the model that was buit on H2O cluster](#Get-access-to-the-model-that-was-buit-on-H2O-cluster)\n",
    "\t* [Import the required libraries](#Import-the-required-libraries)\n",
    "\t* [Connecting to the H2O cluster (with you own credential)](#Connecting-to-the-H2O-cluster-%28with-you-own-credential%29)\n",
    "\t* [Get the build model](#Get-the-build-model)\n",
    "\t* [Show the model details](#Show-the-model-details)\n",
    "\t* [Plot some of the score measures](#Plot-some-of-the-score-measures)\n",
    "\t* [Look at the details of the model hyper-parameters](#Look-at-the-details-of-the-model-hyper-parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get access to the model that was buit on H2O cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "import pandas as pd\n",
    "from ggplot import *\n",
    "import getpass\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the H2O cluster (with you own credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "init() got an unexpected keyword argument 'username'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d8f7d1967349>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m h2o.init(port = 54324,\n\u001b[0;32m      2\u001b[0m          \u001b[0musername\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"aghorbani\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m          password = getpass.getpass())\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: init() got an unexpected keyword argument 'username'"
     ]
    }
   ],
   "source": [
    "\n",
    "h2o.init(port = 54324,\n",
    "         username = \"aghorbani\", \n",
    "         password = getpass.getpass())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "gbm = h2o.get_model(\"yooHoo_my_awesome_GBM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Method\n",
      "Model Key:  yooHoo_my_awesome_GBM\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>model_size_in_bytes</b></td>\n",
       "<td><b>min_depth</b></td>\n",
       "<td><b>max_depth</b></td>\n",
       "<td><b>mean_depth</b></td>\n",
       "<td><b>min_leaves</b></td>\n",
       "<td><b>max_leaves</b></td>\n",
       "<td><b>mean_leaves</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>50.0</td>\n",
       "<td>6053.0</td>\n",
       "<td>3.0</td>\n",
       "<td>3.0</td>\n",
       "<td>3.0</td>\n",
       "<td>4.0</td>\n",
       "<td>7.0</td>\n",
       "<td>4.98</td></tr></table></div>"
      ],
      "text/plain": [
       "    number_of_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    50                 6053                   3            3            3             4             7             4.98"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.123913778631\n",
      "R^2: 0.500759417345\n",
      "LogLoss: 0.418071796476\n",
      "AUC: 0.963541666667\n",
      "Gini: 0.927083333333\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.511206994065: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>46.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.1481</td>\n",
       "<td> (8.0/54.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>4.0</td>\n",
       "<td>60.0</td>\n",
       "<td>0.0625</td>\n",
       "<td> (4.0/64.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>50.0</td>\n",
       "<td>68.0</td>\n",
       "<td>0.1017</td>\n",
       "<td> (12.0/118.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      46   8    0.1481   (8.0/54.0)\n",
       "1      4    60   0.0625   (4.0/64.0)\n",
       "Total  50   68   0.1017   (12.0/118.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.5112070</td>\n",
       "<td>0.9090909</td>\n",
       "<td>63.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4083066</td>\n",
       "<td>0.9495549</td>\n",
       "<td>76.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6009613</td>\n",
       "<td>0.9239130</td>\n",
       "<td>50.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5307022</td>\n",
       "<td>0.8983051</td>\n",
       "<td>61.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.8896264</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.4083066</td>\n",
       "<td>1.0</td>\n",
       "<td>76.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.8896264</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.5112070</td>\n",
       "<td>0.7958258</td>\n",
       "<td>63.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5428605</td>\n",
       "<td>0.8703704</td>\n",
       "<td>58.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.511207     0.909091  63\n",
       "max f2                      0.408307     0.949555  76\n",
       "max f0point5                0.600961     0.923913  50\n",
       "max accuracy                0.530702     0.898305  61\n",
       "max precision               0.889626     1         0\n",
       "max recall                  0.408307     1         76\n",
       "max specificity             0.889626     1         0\n",
       "max absolute_MCC            0.511207     0.795826  63\n",
       "max min_per_class_accuracy  0.542861     0.87037   58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 54.24 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0169492</td>\n",
       "<td>0.8762588</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.03125</td>\n",
       "<td>0.03125</td>\n",
       "<td>84.375</td>\n",
       "<td>84.375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0254237</td>\n",
       "<td>0.8517573</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.015625</td>\n",
       "<td>0.046875</td>\n",
       "<td>84.375</td>\n",
       "<td>84.375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0338983</td>\n",
       "<td>0.8469658</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.015625</td>\n",
       "<td>0.0625</td>\n",
       "<td>84.375</td>\n",
       "<td>84.375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0423729</td>\n",
       "<td>0.8420722</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.015625</td>\n",
       "<td>0.078125</td>\n",
       "<td>84.375</td>\n",
       "<td>84.375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0508475</td>\n",
       "<td>0.8418820</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.015625</td>\n",
       "<td>0.09375</td>\n",
       "<td>84.375</td>\n",
       "<td>84.375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1016949</td>\n",
       "<td>0.8139859</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.09375</td>\n",
       "<td>0.1875</td>\n",
       "<td>84.375</td>\n",
       "<td>84.375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1525424</td>\n",
       "<td>0.7908400</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.09375</td>\n",
       "<td>0.28125</td>\n",
       "<td>84.375</td>\n",
       "<td>84.375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2033898</td>\n",
       "<td>0.7523625</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.09375</td>\n",
       "<td>0.375</td>\n",
       "<td>84.375</td>\n",
       "<td>84.375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3050847</td>\n",
       "<td>0.7000783</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.84375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1875</td>\n",
       "<td>0.5625</td>\n",
       "<td>84.375</td>\n",
       "<td>84.375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4067797</td>\n",
       "<td>0.6304277</td>\n",
       "<td>1.5364583</td>\n",
       "<td>1.7669271</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.9583333</td>\n",
       "<td>0.15625</td>\n",
       "<td>0.71875</td>\n",
       "<td>53.6458333</td>\n",
       "<td>76.6927083</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5546467</td>\n",
       "<td>1.3409091</td>\n",
       "<td>1.6875</td>\n",
       "<td>0.7272727</td>\n",
       "<td>0.9152542</td>\n",
       "<td>0.125</td>\n",
       "<td>0.84375</td>\n",
       "<td>34.0909091</td>\n",
       "<td>68.75</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6016949</td>\n",
       "<td>0.4857287</td>\n",
       "<td>0.921875</td>\n",
       "<td>1.5580986</td>\n",
       "<td>0.5</td>\n",
       "<td>0.8450704</td>\n",
       "<td>0.09375</td>\n",
       "<td>0.9375</td>\n",
       "<td>-7.8125</td>\n",
       "<td>55.8098592</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6949153</td>\n",
       "<td>0.3893930</td>\n",
       "<td>0.6704545</td>\n",
       "<td>1.4390244</td>\n",
       "<td>0.3636364</td>\n",
       "<td>0.7804878</td>\n",
       "<td>0.0625</td>\n",
       "<td>1.0</td>\n",
       "<td>-32.9545455</td>\n",
       "<td>43.9024390</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7966102</td>\n",
       "<td>0.3205043</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2553191</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6808511</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.5319149</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8983051</td>\n",
       "<td>0.2456389</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1132075</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6037736</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.3207547</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1282359</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5423729</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0169492                   0.876259           1.84375   1.84375            1                1                           0.03125         0.03125                    84.375    84.375\n",
       "    2        0.0254237                   0.851757           1.84375   1.84375            1                1                           0.015625        0.046875                   84.375    84.375\n",
       "    3        0.0338983                   0.846966           1.84375   1.84375            1                1                           0.015625        0.0625                     84.375    84.375\n",
       "    4        0.0423729                   0.842072           1.84375   1.84375            1                1                           0.015625        0.078125                   84.375    84.375\n",
       "    5        0.0508475                   0.841882           1.84375   1.84375            1                1                           0.015625        0.09375                    84.375    84.375\n",
       "    6        0.101695                    0.813986           1.84375   1.84375            1                1                           0.09375         0.1875                     84.375    84.375\n",
       "    7        0.152542                    0.79084            1.84375   1.84375            1                1                           0.09375         0.28125                    84.375    84.375\n",
       "    8        0.20339                     0.752363           1.84375   1.84375            1                1                           0.09375         0.375                      84.375    84.375\n",
       "    9        0.305085                    0.700078           1.84375   1.84375            1                1                           0.1875          0.5625                     84.375    84.375\n",
       "    10       0.40678                     0.630428           1.53646   1.76693            0.833333         0.958333                    0.15625         0.71875                    53.6458   76.6927\n",
       "    11       0.5                         0.554647           1.34091   1.6875             0.727273         0.915254                    0.125           0.84375                    34.0909   68.75\n",
       "    12       0.601695                    0.485729           0.921875  1.5581             0.5              0.84507                     0.09375         0.9375                     -7.8125   55.8099\n",
       "    13       0.694915                    0.389393           0.670455  1.43902            0.363636         0.780488                    0.0625          1                          -32.9545  43.9024\n",
       "    14       0.79661                     0.320504           0         1.25532            0                0.680851                    0               1                          -100      25.5319\n",
       "    15       0.898305                    0.245639           0         1.11321            0                0.603774                    0               1                          -100      11.3208\n",
       "    16       1                           0.128236           0         1                  0                0.542373                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.190258911108\n",
      "R^2: 0.238964355567\n",
      "LogLoss: 0.564259656545\n",
      "AUC: 0.797052154195\n",
      "Gini: 0.59410430839\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.38167546561: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>10.0</td>\n",
       "<td>11.0</td>\n",
       "<td>0.5238</td>\n",
       "<td> (11.0/21.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1.0</td>\n",
       "<td>20.0</td>\n",
       "<td>0.0476</td>\n",
       "<td> (1.0/21.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>11.0</td>\n",
       "<td>31.0</td>\n",
       "<td>0.2857</td>\n",
       "<td> (12.0/42.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      10   11   0.5238   (11.0/21.0)\n",
       "1      1    20   0.0476   (1.0/21.0)\n",
       "Total  11   31   0.2857   (12.0/42.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3816755</td>\n",
       "<td>0.7692308</td>\n",
       "<td>29.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3475100</td>\n",
       "<td>0.8898305</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6509552</td>\n",
       "<td>0.7526882</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6509552</td>\n",
       "<td>0.7380952</td>\n",
       "<td>17.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.8120921</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.3475100</td>\n",
       "<td>1.0</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.8120921</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_MCC</td>\n",
       "<td>0.3816755</td>\n",
       "<td>0.4873773</td>\n",
       "<td>29.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5692924</td>\n",
       "<td>0.7142857</td>\n",
       "<td>19.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                      threshold    value     idx\n",
       "--------------------------  -----------  --------  -----\n",
       "max f1                      0.381675     0.769231  29\n",
       "max f2                      0.34751      0.889831  32\n",
       "max f0point5                0.650955     0.752688  17\n",
       "max accuracy                0.650955     0.738095  17\n",
       "max precision               0.812092     1         0\n",
       "max recall                  0.34751      1         32\n",
       "max specificity             0.812092     1         0\n",
       "max absolute_MCC            0.381675     0.487377  29\n",
       "max min_per_class_accuracy  0.569292     0.714286  19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 50.00 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0238095</td>\n",
       "<td>0.8097455</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.0476190</td>\n",
       "<td>100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0238095</td>\n",
       "<td>0.8073988</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0476190</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.8057142</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.0952381</td>\n",
       "<td>100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.8045478</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0952381</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.8030746</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.1428571</td>\n",
       "<td>100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1190476</td>\n",
       "<td>0.7887000</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0952381</td>\n",
       "<td>0.2380952</td>\n",
       "<td>100.0</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.7827134</td>\n",
       "<td>1.0</td>\n",
       "<td>1.7142857</td>\n",
       "<td>0.5</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.2857143</td>\n",
       "<td>0.0</td>\n",
       "<td>71.4285714</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2142857</td>\n",
       "<td>0.7584072</td>\n",
       "<td>1.0</td>\n",
       "<td>1.5555556</td>\n",
       "<td>0.5</td>\n",
       "<td>0.7777778</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.0</td>\n",
       "<td>55.5555556</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3095238</td>\n",
       "<td>0.7013603</td>\n",
       "<td>1.5</td>\n",
       "<td>1.5384615</td>\n",
       "<td>0.75</td>\n",
       "<td>0.7692308</td>\n",
       "<td>0.1428571</td>\n",
       "<td>0.4761905</td>\n",
       "<td>50.0</td>\n",
       "<td>53.8461538</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4047619</td>\n",
       "<td>0.6512064</td>\n",
       "<td>1.5</td>\n",
       "<td>1.5294118</td>\n",
       "<td>0.75</td>\n",
       "<td>0.7647059</td>\n",
       "<td>0.1428571</td>\n",
       "<td>0.6190476</td>\n",
       "<td>50.0</td>\n",
       "<td>52.9411765</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5462237</td>\n",
       "<td>1.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.5</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.0952381</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5952381</td>\n",
       "<td>0.4607982</td>\n",
       "<td>0.5</td>\n",
       "<td>1.28</td>\n",
       "<td>0.25</td>\n",
       "<td>0.64</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.7619048</td>\n",
       "<td>-50.0</td>\n",
       "<td>28.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6904762</td>\n",
       "<td>0.3822856</td>\n",
       "<td>1.5</td>\n",
       "<td>1.3103448</td>\n",
       "<td>0.75</td>\n",
       "<td>0.6551724</td>\n",
       "<td>0.1428571</td>\n",
       "<td>0.9047619</td>\n",
       "<td>50.0</td>\n",
       "<td>31.0344828</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7857143</td>\n",
       "<td>0.3502534</td>\n",
       "<td>0.5</td>\n",
       "<td>1.2121212</td>\n",
       "<td>0.25</td>\n",
       "<td>0.6060606</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.9523810</td>\n",
       "<td>-50.0</td>\n",
       "<td>21.2121212</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8809524</td>\n",
       "<td>0.2622619</td>\n",
       "<td>0.5</td>\n",
       "<td>1.1351351</td>\n",
       "<td>0.25</td>\n",
       "<td>0.5675676</td>\n",
       "<td>0.0476190</td>\n",
       "<td>1.0</td>\n",
       "<td>-50.0</td>\n",
       "<td>13.5135135</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2017950</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift    cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain    cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ------  -----------------  ---------------  --------------------------  --------------  -------------------------  ------  -----------------\n",
       "    1        0.0238095                   0.809745           2       2                  1                1                           0.047619        0.047619                   100     100\n",
       "    2        0.0238095                   0.807399           0       2                  0                1                           0               0.047619                   -100    100\n",
       "    3        0.047619                    0.805714           2       2                  1                1                           0.047619        0.0952381                  100     100\n",
       "    4        0.047619                    0.804548           0       2                  0                1                           0               0.0952381                  -100    100\n",
       "    5        0.0714286                   0.803075           2       2                  1                1                           0.047619        0.142857                   100     100\n",
       "    6        0.119048                    0.7887             2       2                  1                1                           0.0952381       0.238095                   100     100\n",
       "    7        0.166667                    0.782713           1       1.71429            0.5              0.857143                    0.047619        0.285714                   0       71.4286\n",
       "    8        0.214286                    0.758407           1       1.55556            0.5              0.777778                    0.047619        0.333333                   0       55.5556\n",
       "    9        0.309524                    0.70136            1.5     1.53846            0.75             0.769231                    0.142857        0.47619                    50      53.8462\n",
       "    10       0.404762                    0.651206           1.5     1.52941            0.75             0.764706                    0.142857        0.619048                   50      52.9412\n",
       "    11       0.5                         0.546224           1       1.42857            0.5              0.714286                    0.0952381       0.714286                   0       42.8571\n",
       "    12       0.595238                    0.460798           0.5     1.28               0.25             0.64                        0.047619        0.761905                   -50     28\n",
       "    13       0.690476                    0.382286           1.5     1.31034            0.75             0.655172                    0.142857        0.904762                   50      31.0345\n",
       "    14       0.785714                    0.350253           0.5     1.21212            0.25             0.606061                    0.047619        0.952381                   -50     21.2121\n",
       "    15       0.880952                    0.262262           0.5     1.13514            0.25             0.567568                    0.047619        1                          -50     13.5135\n",
       "    16       1                           0.201795           0       1                  0                0.5                         0               1                          -100    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_MSE</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_AUC</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_MSE</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_AUC</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-04-24 21:59:11</td>\n",
       "<td> 0.029 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2482045</td>\n",
       "<td>0.6895519</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4576271</td>\n",
       "<td>0.2517955</td>\n",
       "<td>0.6967511</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-04-24 21:59:12</td>\n",
       "<td> 0.377 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2428983</td>\n",
       "<td>0.6788697</td>\n",
       "<td>0.8265336</td>\n",
       "<td>1.6708984</td>\n",
       "<td>0.2457627</td>\n",
       "<td>0.2477177</td>\n",
       "<td>0.6885502</td>\n",
       "<td>0.7335601</td>\n",
       "<td>1.2307692</td>\n",
       "<td>0.2857143</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-04-24 21:59:12</td>\n",
       "<td> 0.515 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.2386276</td>\n",
       "<td>0.6702683</td>\n",
       "<td>0.8586516</td>\n",
       "<td>1.84375</td>\n",
       "<td>0.1949153</td>\n",
       "<td>0.2453163</td>\n",
       "<td>0.6837258</td>\n",
       "<td>0.7210884</td>\n",
       "<td>1.4</td>\n",
       "<td>0.2619048</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-04-24 21:59:12</td>\n",
       "<td> 0.556 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.2336236</td>\n",
       "<td>0.6601887</td>\n",
       "<td>0.8965567</td>\n",
       "<td>1.84375</td>\n",
       "<td>0.1440678</td>\n",
       "<td>0.2411562</td>\n",
       "<td>0.6753520</td>\n",
       "<td>0.7732426</td>\n",
       "<td>1.5</td>\n",
       "<td>0.2619048</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-04-24 21:59:12</td>\n",
       "<td> 0.580 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.2290777</td>\n",
       "<td>0.6510011</td>\n",
       "<td>0.9215856</td>\n",
       "<td>1.84375</td>\n",
       "<td>0.1271186</td>\n",
       "<td>0.2387331</td>\n",
       "<td>0.6704536</td>\n",
       "<td>0.7789116</td>\n",
       "<td>1.5</td>\n",
       "<td>0.2380952</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-04-24 21:59:14</td>\n",
       "<td> 2.457 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>0.1284502</td>\n",
       "<td>0.4296484</td>\n",
       "<td>0.9632523</td>\n",
       "<td>1.84375</td>\n",
       "<td>0.1016949</td>\n",
       "<td>0.1914070</td>\n",
       "<td>0.5671492</td>\n",
       "<td>0.7891156</td>\n",
       "<td>2.0</td>\n",
       "<td>0.3095238</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-04-24 21:59:14</td>\n",
       "<td> 2.510 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>0.1271981</td>\n",
       "<td>0.4264733</td>\n",
       "<td>0.9638310</td>\n",
       "<td>1.84375</td>\n",
       "<td>0.1016949</td>\n",
       "<td>0.1911954</td>\n",
       "<td>0.5665250</td>\n",
       "<td>0.7913832</td>\n",
       "<td>2.0</td>\n",
       "<td>0.3095238</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-04-24 21:59:14</td>\n",
       "<td> 2.603 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>0.1261645</td>\n",
       "<td>0.4237487</td>\n",
       "<td>0.9638310</td>\n",
       "<td>1.84375</td>\n",
       "<td>0.1016949</td>\n",
       "<td>0.1915243</td>\n",
       "<td>0.5669331</td>\n",
       "<td>0.7913832</td>\n",
       "<td>2.0</td>\n",
       "<td>0.3095238</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-04-24 21:59:14</td>\n",
       "<td> 2.631 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>0.1253524</td>\n",
       "<td>0.4215472</td>\n",
       "<td>0.9629630</td>\n",
       "<td>1.84375</td>\n",
       "<td>0.1016949</td>\n",
       "<td>0.1911480</td>\n",
       "<td>0.5659702</td>\n",
       "<td>0.7970522</td>\n",
       "<td>2.0</td>\n",
       "<td>0.2857143</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-04-24 21:59:14</td>\n",
       "<td> 2.660 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.1239138</td>\n",
       "<td>0.4180718</td>\n",
       "<td>0.9635417</td>\n",
       "<td>1.84375</td>\n",
       "<td>0.1016949</td>\n",
       "<td>0.1902589</td>\n",
       "<td>0.5642597</td>\n",
       "<td>0.7970522</td>\n",
       "<td>2.0</td>\n",
       "<td>0.2857143</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_MSE    training_logloss    training_AUC    training_lift    training_classification_error    validation_MSE    validation_logloss    validation_AUC    validation_lift    validation_classification_error\n",
       "---  -------------------  ----------  -----------------  --------------  ------------------  --------------  ---------------  -------------------------------  ----------------  --------------------  ----------------  -----------------  ---------------------------------\n",
       "     2016-04-24 21:59:11  0.029 sec   0.0                0.248204538926  0.689551947775      0.5             1.0              0.457627118644                   0.251795461074    0.696751059504        0.5               1.0                0.5\n",
       "     2016-04-24 21:59:12  0.377 sec   1.0                0.242898330027  0.678869727206      0.826533564815  1.6708984375     0.245762711864                   0.247717709457    0.688550169114        0.733560090703    1.23076923077      0.285714285714\n",
       "     2016-04-24 21:59:12  0.515 sec   2.0                0.238627603838  0.670268277151      0.85865162037   1.84375          0.194915254237                   0.245316335056    0.683725845123        0.721088435374    1.4                0.261904761905\n",
       "     2016-04-24 21:59:12  0.556 sec   3.0                0.233623638735  0.660188700158      0.896556712963  1.84375          0.14406779661                    0.241156216002    0.675351996201        0.773242630385    1.5                0.261904761905\n",
       "     2016-04-24 21:59:12  0.580 sec   4.0                0.229077747231  0.651001126825      0.921585648148  1.84375          0.127118644068                   0.238733095014    0.670453580007        0.778911564626    1.5                0.238095238095\n",
       "---  ---                  ---         ---                ---             ---                 ---             ---              ---                              ---               ---                   ---               ---                ---\n",
       "     2016-04-24 21:59:14  2.457 sec   46.0               0.128450214693  0.429648440836      0.963252314815  1.84375          0.101694915254                   0.191407016578    0.567149182451        0.789115646259    2.0                0.309523809524\n",
       "     2016-04-24 21:59:14  2.510 sec   47.0               0.127198093331  0.426473266028      0.963831018519  1.84375          0.101694915254                   0.191195385069    0.566524973606        0.791383219955    2.0                0.309523809524\n",
       "     2016-04-24 21:59:14  2.603 sec   48.0               0.126164544292  0.42374873486       0.963831018519  1.84375          0.101694915254                   0.191524274305    0.566933125075        0.791383219955    2.0                0.309523809524\n",
       "     2016-04-24 21:59:14  2.631 sec   49.0               0.125352367211  0.421547241739      0.962962962963  1.84375          0.101694915254                   0.191147994459    0.5659701674          0.797052154195    2.0                0.285714285714\n",
       "     2016-04-24 21:59:14  2.660 sec   50.0               0.123913778631  0.418071796476      0.963541666667  1.84375          0.101694915254                   0.190258911108    0.564259656545        0.797052154195    2.0                0.285714285714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Calls</td>\n",
       "<td>54.9902153</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2353649</td></tr>\n",
       "<tr><td>Education</td>\n",
       "<td>44.5768242</td>\n",
       "<td>0.8106319</td>\n",
       "<td>0.1907943</td></tr>\n",
       "<tr><td>FamilySize</td>\n",
       "<td>44.1950188</td>\n",
       "<td>0.8036888</td>\n",
       "<td>0.1891602</td></tr>\n",
       "<tr><td>Gender</td>\n",
       "<td>35.7124825</td>\n",
       "<td>0.6494334</td>\n",
       "<td>0.1528539</td></tr>\n",
       "<tr><td>Income</td>\n",
       "<td>30.4329967</td>\n",
       "<td>0.5534257</td>\n",
       "<td>0.1302570</td></tr>\n",
       "<tr><td>Visits</td>\n",
       "<td>11.8706903</td>\n",
       "<td>0.2158691</td>\n",
       "<td>0.0508080</td></tr>\n",
       "<tr><td>Age</td>\n",
       "<td>11.8598614</td>\n",
       "<td>0.2156722</td>\n",
       "<td>0.0507617</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "Calls       54.9902                1                    0.235365\n",
       "Education   44.5768                0.810632             0.190794\n",
       "FamilySize  44.195                 0.803689             0.18916\n",
       "Gender      35.7125                0.649433             0.152854\n",
       "Income      30.433                 0.553426             0.130257\n",
       "Visits      11.8707                0.215869             0.050808\n",
       "Age         11.8599                0.215672             0.0507617"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some of the score measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqAAAAHzCAYAAAD/zq8BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngpoCqoxLU14AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff9669c7090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8794321435801)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_history = pd.melt(gbm.scoring_history(), \n",
    "                          id_vars=['number_of_trees'], \n",
    "                          value_vars=['training_AUC', 'validation_AUC'])\n",
    "                         \n",
    "p = ggplot(aes(x='number_of_trees', y='value', color='variable'), data=scoring_history) \n",
    "p = p + geom_line()\n",
    "p = p + xlab(\"number of trees\") + ylab(\"AUC\")\n",
    "p "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the details of the model hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>balance_classes</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build_tree_one_node</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>checkpoint</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_sampling_factors</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_sample_rate</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_sample_rate_per_tree</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distribution</th>\n",
       "      <td>bernoulli</td>\n",
       "      <td>AUTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold_assignment</th>\n",
       "      <td>AUTO</td>\n",
       "      <td>AUTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold_column</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignore_const_cols</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignored_columns</th>\n",
       "      <td>[CustID]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep_cross_validation_predictions</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learn_rate</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_after_balance_size</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_confusion_matrix_size</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_hit_ratio_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_runtime_secs</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_rows</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_id</th>\n",
       "      <td>{u'URL': u'/4/Models/yooHoo_my_awesome_GBM', u'type': u'Key&lt;Model&gt;...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbins</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbins_cats</th>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbins_top_level</th>\n",
       "      <td>1024</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nfolds</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ntrees</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offset_column</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile_alpha</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_stopping</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response_column</th>\n",
       "      <td>{u'is_member_of_frames': None, u'column_name': u'Churn', u'__meta'...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_rate</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_each_iteration</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_tree_interval</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seed</th>\n",
       "      <td>-7692078340785586861</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopping_metric</th>\n",
       "      <td>AUTO</td>\n",
       "      <td>AUTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopping_rounds</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopping_tolerance</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_frame</th>\n",
       "      <td>{u'URL': u'/4/Frames/train_frame', u'type': u'Key&lt;Frame&gt;', u'name'...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweedie_power</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation_frame</th>\n",
       "      <td>{u'URL': u'/4/Frames/valid_frame', u'type': u'Key&lt;Frame&gt;', u'name'...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights_column</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  actual  \\\n",
       "balance_classes                                                                                    False   \n",
       "build_tree_one_node                                                                                False   \n",
       "checkpoint                                                                                          None   \n",
       "class_sampling_factors                                                                              None   \n",
       "col_sample_rate                                                                                      0.7   \n",
       "col_sample_rate_per_tree                                                                               1   \n",
       "distribution                                                                                   bernoulli   \n",
       "fold_assignment                                                                                     AUTO   \n",
       "fold_column                                                                                         None   \n",
       "ignore_const_cols                                                                                   True   \n",
       "ignored_columns                                                                                 [CustID]   \n",
       "keep_cross_validation_predictions                                                                  False   \n",
       "learn_rate                                                                                          0.03   \n",
       "max_after_balance_size                                                                                 5   \n",
       "max_confusion_matrix_size                                                                             20   \n",
       "max_depth                                                                                              3   \n",
       "max_hit_ratio_k                                                                                        0   \n",
       "max_runtime_secs                                                                                       0   \n",
       "min_rows                                                                                              10   \n",
       "model_id                           {u'URL': u'/4/Models/yooHoo_my_awesome_GBM', u'type': u'Key<Model>...   \n",
       "nbins                                                                                                 20   \n",
       "nbins_cats                                                                                          1024   \n",
       "nbins_top_level                                                                                     1024   \n",
       "nfolds                                                                                                 0   \n",
       "ntrees                                                                                                50   \n",
       "offset_column                                                                                       None   \n",
       "quantile_alpha                                                                                       0.5   \n",
       "r2_stopping                                                                                     0.999999   \n",
       "response_column                    {u'is_member_of_frames': None, u'column_name': u'Churn', u'__meta'...   \n",
       "sample_rate                                                                                          0.8   \n",
       "score_each_iteration                                                                               False   \n",
       "score_tree_interval                                                                                    0   \n",
       "seed                                                                                -7692078340785586861   \n",
       "stopping_metric                                                                                     AUTO   \n",
       "stopping_rounds                                                                                        0   \n",
       "stopping_tolerance                                                                                 0.001   \n",
       "training_frame                     {u'URL': u'/4/Frames/train_frame', u'type': u'Key<Frame>', u'name'...   \n",
       "tweedie_power                                                                                        1.5   \n",
       "validation_frame                   {u'URL': u'/4/Frames/valid_frame', u'type': u'Key<Frame>', u'name'...   \n",
       "weights_column                                                                                      None   \n",
       "\n",
       "                                    default  \n",
       "balance_classes                       False  \n",
       "build_tree_one_node                   False  \n",
       "checkpoint                             None  \n",
       "class_sampling_factors                 None  \n",
       "col_sample_rate                           1  \n",
       "col_sample_rate_per_tree                  1  \n",
       "distribution                           AUTO  \n",
       "fold_assignment                        AUTO  \n",
       "fold_column                            None  \n",
       "ignore_const_cols                      True  \n",
       "ignored_columns                        None  \n",
       "keep_cross_validation_predictions     False  \n",
       "learn_rate                              0.1  \n",
       "max_after_balance_size                    5  \n",
       "max_confusion_matrix_size                20  \n",
       "max_depth                                 5  \n",
       "max_hit_ratio_k                           0  \n",
       "max_runtime_secs                          0  \n",
       "min_rows                                 10  \n",
       "model_id                               None  \n",
       "nbins                                    20  \n",
       "nbins_cats                             1024  \n",
       "nbins_top_level                        1024  \n",
       "nfolds                                    0  \n",
       "ntrees                                   50  \n",
       "offset_column                          None  \n",
       "quantile_alpha                          0.5  \n",
       "r2_stopping                        0.999999  \n",
       "response_column                        None  \n",
       "sample_rate                               1  \n",
       "score_each_iteration                  False  \n",
       "score_tree_interval                       0  \n",
       "seed                                     -1  \n",
       "stopping_metric                        AUTO  \n",
       "stopping_rounds                           0  \n",
       "stopping_tolerance                    0.001  \n",
       "training_frame                         None  \n",
       "tweedie_power                           1.5  \n",
       "validation_frame                       None  \n",
       "weights_column                         None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gbm.params).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
